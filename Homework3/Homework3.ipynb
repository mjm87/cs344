{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "s6rLh67wg1G3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** 1. XOR Function**\n",
        "\n",
        "In class we attempted to design a neural network that could learn the XOR function, and while we were able to do so using non-linear functions and fixing the values ourselves, it was a far more challenging, impossible problem for the early neural networks that attempted to learn it. Part of the reason was that we needed the non-linear functions (such as tanh or reLu),  however, more importantly the early networks didn't have any form of back-propagation which was essential for the neural networks to be able to learn even what might the almost trivial XOR function. Without being able to pass the error backwards and impact all the layers of the net, it was impossible for the XOR function to be learned."
      ]
    },
    {
      "metadata": {
        "id": "3zpF8L1hi3u9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Load / Manipulate the Boston Housing Dataset**\n",
        "\n",
        "The first step will be to read in the Boston Housing data from the CSV"
      ]
    },
    {
      "metadata": {
        "id": "PaSeq_geiDy-",
        "colab_type": "code",
        "outputId": "959af563-b8bb-4a4a-e36d-45517ac04a9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "boston_df = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\")\n",
        "boston_df.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>b</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
              "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
              "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
              "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
              "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
              "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
              "\n",
              "        b  lstat  medv  \n",
              "0  396.90   4.98  24.0  \n",
              "1  396.90   9.14  21.6  \n",
              "2  392.83   4.03  34.7  \n",
              "3  394.63   2.94  33.4  \n",
              "4  396.90   5.33  36.2  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "I7Cky89rjLwW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To look at the dimensions of the dataset, we can just look at the shape of the dataframe.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CwreelddmiZA",
        "colab_type": "code",
        "outputId": "209ad4a5-0071-481b-d69b-57830012b9ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(boston_df.shape)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KADJJdQBpKNS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Which shows that we have 14 different features we're interested in (\"crim\", \"nox\", \"ptratio\", etc) and 506 rows of data.\n",
        "\n",
        "\n",
        "To split the available data into a learning, validation and test set, we can use scikit's train_test_split() function."
      ]
    },
    {
      "metadata": {
        "id": "QktOSaJYjSYC",
        "colab_type": "code",
        "outputId": "2a8a300f-9aef-4099-ce26-3b19b7567438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# using an 80/20 split since that seemed recommended as a safe bet\n",
        "# https://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio\n",
        "train, test = train_test_split(boston_df, test_size=0.2)\n",
        "test, validation = train_test_split(test, test_size=0.2)\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "print(validation.shape)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 14)\n",
            "(81, 14)\n",
            "(21, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "obEj99bGu31D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If we wanted to add a new feature to this data set, one option would be to look at something like whether or not the crime rate was above average. I know that if I were evaluating households, I wouldn't really know what level of crime would be \"acceptable\", but if it were \"above average\" I would at least be concerned."
      ]
    },
    {
      "metadata": {
        "id": "vfIwsOltv_70",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "average_crime_rate = sum(boston_df[\"crim\"]) / len(boston_df)\n",
        "boston_df[\"above_average_crime\"] = boston_df[\"crim\"] > average_crime_rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eWfeWAGFxNRj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}